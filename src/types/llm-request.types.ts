type LlmRequestConfig = {
    streaming: boolean,
    model?: string
}
